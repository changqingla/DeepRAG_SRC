# DeepRAG æ–‡æ¡£åˆ†å—æ¨¡å—

## ğŸ“– æ¦‚è¿°

DeepRAG æ–‡æ¡£åˆ†å—æ¨¡å—åŸºäº DeepRAG çš„æ·±åº¦æ–‡æ¡£ç†è§£ç®—æ³•ï¼Œæä¾›å®Œæ•´çš„æ–‡æ¡£åˆ†å—åŠŸèƒ½ã€‚è¯¥æ¨¡å—å¤ç”¨äº†æ•´ä¸ª DeepRAG å¤„ç†æµæ°´çº¿ï¼ŒåŒ…æ‹¬ OCRã€ç‰ˆé¢è¯†åˆ«ã€è¡¨æ ¼ç»“æ„è¯†åˆ«å’Œæ™ºèƒ½åˆ†å—ç­–ç•¥ï¼Œä¸ºæ–‡æ¡£å¤„ç†æä¾›é«˜è´¨é‡çš„åˆ†å—ç»“æœã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- **ğŸ”§ å¤šæ ¼å¼æ”¯æŒ**: æ”¯æŒ PDFã€Wordã€Excelã€PowerPointã€Markdownã€TXTã€HTML ç­‰å¤šç§æ–‡æ¡£æ ¼å¼
- **ğŸ§  æ™ºèƒ½è§£æ**: é›†æˆ DeepRAG çš„æ·±åº¦æ–‡æ¡£ç†è§£ç®—æ³•ï¼Œæ”¯æŒ 10 ç§ä¸“ä¸šè§£æå™¨
- **ğŸ“Š ç‰ˆé¢è¯†åˆ«**: æ™ºèƒ½ç‰ˆé¢è¯†åˆ«å’Œå†…å®¹æå–ï¼Œæ”¯æŒè¡¨æ ¼å’Œå›¾åƒçš„ç»“æ„åŒ–å¤„ç†
- **âš¡ é«˜æ•ˆåˆ†å—**: åŸºäºè¯­ä¹‰çš„æ™ºèƒ½åˆ†å—ç­–ç•¥ï¼Œä¿æŒå†…å®¹å®Œæ•´æ€§å’Œä¸Šä¸‹æ–‡è¿è´¯æ€§
- **ğŸ”„ å¼‚æ­¥å¤„ç†**: æ”¯æŒå¼‚æ­¥å’Œæ‰¹é‡å¤„ç†ï¼Œæé«˜å¤„ç†æ•ˆç‡
- **ğŸ¯ çµæ´»é…ç½®**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œé€‚åº”ä¸åŒæ–‡æ¡£ç±»å‹å’Œå¤„ç†éœ€æ±‚
- **ğŸ“ˆ è´¨é‡åˆ†æ**: å†…ç½®åˆ†å—è´¨é‡åˆ†æå’Œç»Ÿè®¡åŠŸèƒ½
- **ğŸ–¥ï¸ å‘½ä»¤è¡Œå·¥å…·**: å®Œæ•´çš„å‘½ä»¤è¡Œç•Œé¢ï¼Œæ–¹ä¾¿æ‰¹é‡æ“ä½œ

## ğŸ“ æ¨¡å—ç»“æ„

```
chunk/
â”œâ”€â”€ README.md                    # æœ¬æ–‡æ¡£
â”œâ”€â”€ __init__.py                  # æ¨¡å—åˆå§‹åŒ–æ–‡ä»¶
â”œâ”€â”€ document_chunker.py          # æ ¸å¿ƒæ–‡æ¡£åˆ†å—å™¨ç±»
â”œâ”€â”€ chunker_utils.py             # å·¥å…·å‡½æ•°å’Œè¾…åŠ©ç±»
â”œâ”€â”€ chunk_cli.py                 # å‘½ä»¤è¡Œå·¥å…·
â”œâ”€â”€ config_examples.json         # é…ç½®ç¤ºä¾‹æ–‡ä»¶
â””â”€â”€ markdown_chunks.json         # ç¤ºä¾‹åˆ†å—ç»“æœ
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from document_chunker import DocumentChunker
from chunker_utils import ChunkingConfig

# åˆ›å»ºåˆ†å—å™¨
chunker = DocumentChunker(
    parser_type="general",
    chunk_token_num=256,
    language="Chinese"
)

# åˆ†å—æ–‡æ¡£
chunks = chunker.chunk_document("document.pdf")
print(f"ç”Ÿæˆäº† {len(chunks)} ä¸ªåˆ†å—")

# æŸ¥çœ‹åˆ†å—å†…å®¹
for i, chunk in enumerate(chunks[:3]):
    print(f"åˆ†å— {i+1}: {chunk['content_with_weight'][:100]}...")
```

### 2. ä½¿ç”¨é…ç½®ç±»

```python
from chunker_utils import ChunkingConfig

# åˆ›å»ºé…ç½®
config = ChunkingConfig(
    parser_type="paper",
    chunk_token_num=512,
    delimiter="\n.!?",
    language="English"
)

# ä½¿ç”¨é…ç½®åˆ›å»ºåˆ†å—å™¨
chunker = DocumentChunker(**config.to_dict())
chunks = chunker.chunk_document("research_paper.pdf")
```

### 3. å¼‚æ­¥å¤„ç†

```python
import asyncio

async def process_document():
    chunker = DocumentChunker()
    chunks = await chunker.chunk_document_async("document.pdf")
    return chunks

# è¿è¡Œå¼‚æ­¥å¤„ç†
chunks = asyncio.run(process_document())
```

### 4. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£
file_paths = ["doc1.pdf", "doc2.docx", "doc3.pptx"]
results = chunker.chunk_batch(file_paths)

for file_path, chunks in results.items():
    print(f"{file_path}: {len(chunks)} ä¸ªåˆ†å—")
```

## ğŸ”§ æ”¯æŒçš„è§£æå™¨

| è§£æå™¨ç±»å‹ | é€‚ç”¨åœºæ™¯ | ç‰¹ç‚¹ |
|-----------|---------|------|
| **general** | é€šç”¨æ–‡æ¡£ | é€‚ç”¨äºå¤§å¤šæ•°æ–‡æ¡£ç±»å‹ |
| **paper** | å­¦æœ¯è®ºæ–‡ | ä¼˜åŒ–è®ºæ–‡ç»“æ„è¯†åˆ« |
| **book** | ä¹¦ç±æ–‡æ¡£ | é€‚åˆé•¿æ–‡æ¡£å’Œç« èŠ‚ç»“æ„ |
| **presentation** | æ¼”ç¤ºæ–‡ç¨¿ | é’ˆå¯¹ PPT ç­‰æ¼”ç¤ºæ–‡æ¡£ |
| **manual** | æŠ€æœ¯æ‰‹å†Œ | é€‚åˆæŠ€æœ¯æ–‡æ¡£å’Œè¯´æ˜ä¹¦ |
| **laws** | æ³•å¾‹æ–‡æ¡£ | ä¸“é—¨å¤„ç†æ³•å¾‹æ¡æ–‡ |
| **qa** | é—®ç­”æ–‡æ¡£ | ä¼˜åŒ–é—®ç­”æ ¼å¼è¯†åˆ« |
| **table** | è¡¨æ ¼æ•°æ® | ä¸“é—¨å¤„ç†è¡¨æ ¼å†…å®¹ |
| **one** | å•é¡µæ–‡æ¡£ | é€‚åˆå•é¡µæˆ–ç®€çŸ­æ–‡æ¡£ |
| **email** | é‚®ä»¶æ–‡æ¡£ | é’ˆå¯¹é‚®ä»¶æ ¼å¼ä¼˜åŒ– |

## ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼

| æ ¼å¼ç±»å‹ | æ‰©å±•å | è¯´æ˜ |
|---------|--------|------|
| **PDF** | `.pdf` | æ”¯æŒæ–‡æœ¬å’Œå›¾åƒ PDF |
| **Word** | `.docx`, `.doc` | Microsoft Word æ–‡æ¡£ |
| **Excel** | `.xlsx`, `.xls` | Excel è¡¨æ ¼æ–‡ä»¶ |
| **PowerPoint** | `.pptx`, `.ppt` | PowerPoint æ¼”ç¤ºæ–‡ç¨¿ |
| **æ–‡æœ¬** | `.txt`, `.md` | çº¯æ–‡æœ¬å’Œ Markdown |
| **ç½‘é¡µ** | `.html`, `.htm` | HTML ç½‘é¡µæ–‡ä»¶ |

## ğŸ› ï¸ å‘½ä»¤è¡Œä½¿ç”¨

### åŸºæœ¬å‘½ä»¤

```bash
# åˆ†å—å•ä¸ªæ–‡æ¡£
python chunk_cli.py document.pdf --parser paper --output chunks.json

# æ‰¹é‡å¤„ç†ç›®å½•
python chunk_cli.py --batch ./documents --parser book --format txt

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
python chunk_cli.py document.docx --tokens 512 --language English

# è·å–è§£æå™¨æ¨è
python chunk_cli.py document.pdf --recommend-parser

# æ˜¾ç¤ºåˆ†å—é¢„è§ˆå’Œç»Ÿè®¡
python chunk_cli.py document.pdf --preview --stats
```

### é«˜çº§åŠŸèƒ½

```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶
python chunk_cli.py document.pdf --config config.json

# ä¿å­˜é…ç½®
python chunk_cli.py document.pdf --save-config my_config.json

# è¯¦ç»†æ—¥å¿—è¾“å‡º
python chunk_cli.py document.pdf --verbose

# è‡ªå®šä¹‰åˆ†å—å‚æ•°
python chunk_cli.py document.pdf \
    --parser paper \
    --tokens 512 \
    --delimiter "\n.!?" \
    --language English \
    --from-page 1 \
    --to-page 10
```

## âš™ï¸ é…ç½®å‚æ•°

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `parser_type` | str | "general" | è§£æå™¨ç±»å‹ |
| `chunk_token_num` | int | 256 | æ¯ä¸ªåˆ†å—çš„æœ€å¤§ token æ•° |
| `delimiter` | str | "\nã€‚ï¼›ï¼ï¼Ÿ" | æ–‡æœ¬åˆ†å‰²ç¬¦ |
| `language` | str | "Chinese" | æ–‡æ¡£è¯­è¨€ |
| `layout_recognize` | str | "DeepDOC" | ç‰ˆé¢è¯†åˆ«æ–¹æ³• |
| `zoomin` | int | 3 | OCR ç¼©æ”¾å› å­ |
| `from_page` | int | 0 | èµ·å§‹é¡µç  |
| `to_page` | int | 100000 | ç»“æŸé¡µç  |

### é…ç½®ç¤ºä¾‹

æŸ¥çœ‹ `config_examples.json` æ–‡ä»¶è·å–ä¸åŒåœºæ™¯çš„é…ç½®ç¤ºä¾‹ï¼š

```json
{
  "academic_paper": {
    "parser_type": "paper",
    "chunk_token_num": 512,
    "delimiter": "\n.!?",
    "language": "English"
  },
  "chinese_book": {
    "parser_type": "book",
    "chunk_token_num": 256,
    "delimiter": "\nã€‚ï¼›ï¼ï¼Ÿ",
    "language": "Chinese"
  }
}
```

## ğŸ“Š åˆ†å—è´¨é‡åˆ†æ

### ç»Ÿè®¡ä¿¡æ¯

```python
# è·å–åˆ†å—ç»Ÿè®¡
stats = chunker.get_chunk_statistics(chunks)
print(f"æ€»åˆ†å—æ•°: {stats['total_chunks']}")
print(f"å¹³å‡é•¿åº¦: {stats['avg_length']}")
print(f"token åˆ†å¸ƒ: {stats['token_distribution']}")
```

### è´¨é‡åˆ†æ

```python
from chunker_utils import ChunkAnalyzer

# åˆ†æåˆ†å—è´¨é‡
analyzer = ChunkAnalyzer()
quality_report = analyzer.analyze_chunk_quality(chunks)

print(f"è´¨é‡è¯„åˆ†: {quality_report['quality_score']}")
print(f"ä¼˜åŒ–å»ºè®®: {quality_report['recommendations']}")
```

## ğŸ” å·¥å…·ç±»åŠŸèƒ½

### æ–‡ä»¶ç±»å‹æ£€æµ‹

```python
from chunker_utils import FileTypeDetector

# æ£€æµ‹æ–‡ä»¶ç±»å‹
file_type = FileTypeDetector.detect_file_type("document.pdf")
print(f"æ–‡ä»¶ç±»å‹: {file_type}")

# è·å–è§£æå™¨æ¨è
recommendations = FileTypeDetector.recommend_parser("document.pdf")
print(f"æ¨èè§£æå™¨: {recommendations}")
```

### ç»“æœæ ¼å¼åŒ–

```python
from chunker_utils import ResultFormatter

# æ ¼å¼åŒ–æ˜¾ç¤º
formatted = ResultFormatter.format_chunks_for_display(chunks)
for chunk in formatted[:3]:
    print(f"åˆ†å— {chunk['chunk_id']}: {chunk['content_preview']}")

# ç”ŸæˆæŠ¥å‘Š
report = ResultFormatter.create_summary_report(chunks, processing_time=2.5)
print(report)
```

## ğŸš¨ é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯

1. **æ–‡ä»¶ä¸å­˜åœ¨**: æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
2. **æ ¼å¼ä¸æ”¯æŒ**: ç¡®è®¤æ–‡ä»¶æ ¼å¼åœ¨æ”¯æŒåˆ—è¡¨ä¸­
3. **å†…å­˜ä¸è¶³**: å‡å°‘ `chunk_token_num` æˆ–åˆ†æ‰¹å¤„ç†
4. **OCR å¤±è´¥**: è°ƒæ•´ `zoomin` å‚æ•°æˆ–æ£€æŸ¥å›¾åƒè´¨é‡

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# éªŒè¯å‚æ•°
validation_result = chunker.validate_parameters()
if not validation_result['valid']:
    print(f"å‚æ•°é”™è¯¯: {validation_result['errors']}")

# ä½¿ç”¨è¿›åº¦å›è°ƒ
def progress_callback(progress, msg):
    print(f"è¿›åº¦: {progress:.1%} - {msg}")

chunker = DocumentChunker(progress_callback=progress_callback)
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„è§£æå™¨

- **å­¦æœ¯è®ºæ–‡**: ä½¿ç”¨ `paper` è§£æå™¨
- **æŠ€æœ¯æ–‡æ¡£**: ä½¿ç”¨ `manual` è§£æå™¨
- **è¡¨æ ¼æ•°æ®**: ä½¿ç”¨ `table` è§£æå™¨
- **é€šç”¨æ–‡æ¡£**: ä½¿ç”¨ `general` è§£æå™¨

### 2. ä¼˜åŒ–åˆ†å—å¤§å°

- **çŸ­æ–‡æ¡£**: 128-256 tokens
- **é•¿æ–‡æ¡£**: 256-512 tokens
- **æŠ€æœ¯æ–‡æ¡£**: 384-512 tokens
- **å¯¹è¯æ•°æ®**: 128-256 tokens

### 3. è¯­è¨€è®¾ç½®

- ä¸­æ–‡æ–‡æ¡£ä½¿ç”¨ `language="Chinese"`
- è‹±æ–‡æ–‡æ¡£ä½¿ç”¨ `language="English"`
- æ ¹æ®ä¸»è¦è¯­è¨€é€‰æ‹©åˆé€‚çš„åˆ†éš”ç¬¦

### 4. æ€§èƒ½ä¼˜åŒ–

- å¤§æ–‡æ¡£ä½¿ç”¨å¼‚æ­¥å¤„ç†
- æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£
- åˆç†è®¾ç½®é¡µé¢èŒƒå›´
- æ ¹æ®éœ€è¦è°ƒæ•´ OCR å‚æ•°

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚

## ğŸ“„ è®¸å¯è¯

Apache 2.0 License